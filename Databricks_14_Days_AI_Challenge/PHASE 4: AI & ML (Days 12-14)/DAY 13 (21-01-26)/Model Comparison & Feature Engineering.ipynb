{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "04c6d2be-976a-44dc-8c51-256738524e09",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#STEP 1:Problem Framing & Experiment Design\n",
    "\n",
    "üìò Learn Covered\n",
    "\n",
    "‚úî Training multiple models (design stage ‚Äì before coding)\n",
    "\n",
    "üõ†Ô∏è Task Covered\n",
    "\n",
    "‚úî Prepare to train 3 different models (design + alignment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d0d12e05-8eda-4312-bc75-0b12824b40a2",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Problem Statement"
    }
   },
   "source": [
    "#Problem Statement:Can we predict how many purchases a product will receive based on its visibility and conversion behavior?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "27c9bc5c-c61b-43ef-a673-02e8949fac36",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Dataset Understanding (Confirmed)\n",
    "\n",
    "Source table: gold.products\n",
    "\n",
    "Column\tRole\n",
    "\n",
    "views\t-> Feature\n",
    "\n",
    "conversion_rate\t-> Feature\n",
    "\n",
    "purchases\t-> Target\n",
    "\n",
    "event_date\tIgnored \n",
    "\n",
    "product_id\tIgnored\n",
    "\n",
    "revenue\tIgnored "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "91f1c93e-a25f-4952-bd29-a92422f7dcf9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Final ML Design\n",
    "\n",
    "üéØ Target Variable\n",
    "\n",
    "purchases\n",
    "\n",
    "üß† Input Features\n",
    "\n",
    "views\n",
    "\n",
    "conversion_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "64decaae-394f-4a42-86da-eb5d13473a95",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Model Families Planned (No Training Yet)\n",
    "\n",
    "We will compare model families\n",
    "\n",
    "\n",
    "Linear Regression\t-> Simple, interpretable baseline\n",
    "\n",
    "Decision Tree\t-> Captures non-linearity\n",
    "\n",
    "Random Forest\t-> More robust ensemble\n",
    "\n",
    "‚úî Same data\n",
    "\n",
    "‚úî Same features\n",
    "\n",
    "‚úî Same metric\n",
    "\n",
    "‚úî Same MLflow experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d22013af-e82b-4cf3-a373-af4904cc4077",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#STEP 2 Train 3 Different Models (Scikit-Learn) + MLflow Tracking\n",
    "\n",
    "Learn Covered\n",
    "\n",
    "‚úî Training multiple models\n",
    "\n",
    "‚úî Comparing models under the same experiment\n",
    "\n",
    "üõ†Ô∏è Task Covered\n",
    "\n",
    "‚úî Task 1 ‚Äì Train 3 different models\n",
    "\n",
    "‚ö†Ô∏è In this step we ONLY train & log models\n",
    "\n",
    "‚ùå No tuning\n",
    "\n",
    "‚ùå No Spark pipeline yet\n",
    "\n",
    "‚ùå No model selection yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c7c9dc04-07cd-4195-9341-027d763990d7",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "MLflow Experiment"
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "mlflow.set_experiment(\"/Users/ram.katneni@gmail.com/day13_model_comparison\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "968869ff-fe0a-47ec-80f1-28e117886e45",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "‚úî Single experiment\n",
    "\n",
    "‚úî Comparable runs\n",
    "\n",
    "‚úî Clean UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "91a70275-6183-4e6c-8cf0-567df659474f",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Prepare Data"
    }
   },
   "outputs": [],
   "source": [
    "df = spark.table(\"gold.products\").toPandas()\n",
    "\n",
    "X = df[[\"views\", \"conversion_rate\"]]\n",
    "y = df[\"purchases\"]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f94e493e-0f27-413a-8654-499f142d75ee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "‚úî Same split for all models\n",
    "\n",
    "‚úî Fair comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7e46c289-b461-4ead-9e1f-eda4214c1022",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Define Model Candidates"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "models = {\n",
    "    \"linear_regression\": LinearRegression(),\n",
    "    \"decision_tree\": DecisionTreeRegressor(max_depth=5, random_state=42),\n",
    "    \"random_forest\": RandomForestRegressor(n_estimators=50, random_state=42)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c98e13ab-2e09-4735-8093-082c836dcbd5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "‚úî Different model families\n",
    "\n",
    "‚úî No hyperparameter tuning yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3b84f3d9-07dc-4ff0-bd99-35bc12376369",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Train & Log Each Model"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "for name, model in models.items():\n",
    "    with mlflow.start_run(run_name=name):\n",
    "        mlflow.log_param(\"model_type\", name)\n",
    "        mlflow.log_param(\"features\", \"views, conversion_rate\")\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        preds = model.predict(X_test)\n",
    "        r2 = r2_score(y_test, preds)\n",
    "\n",
    "        mlflow.log_metric(\"r2_score\", r2)\n",
    "        mlflow.sklearn.log_model(model, \"model\")\n",
    "\n",
    "        print(f\"{name} R¬≤: {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c7ba3ca2-d232-485a-a400-595b3e89d4c4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "‚úî Same metric\n",
    "\n",
    "‚úî Same dataset\n",
    "\n",
    "‚úî Same logging format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3dd880ad-efd1-42f0-b442-62d4af8affd3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#STEP 3 Compare Model Metrics in MLflow UI\n",
    "üìò Learn Covered\n",
    "\n",
    "‚úî Experiment tracking\n",
    "‚úî Model comparison using MLflow\n",
    "\n",
    "üõ†Ô∏è Task Covered\n",
    "\n",
    "‚úî Task 2 ‚Äì Compare metrics in MLflow\n",
    "\n",
    "‚ö†Ô∏è This step is analysis only\n",
    "‚ùå No new training\n",
    "‚ùå No code changes\n",
    "‚ùå No Spark pipeline yet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "528f71c9-0c69-4dcb-9a73-aa002fbd0c0a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# STEP 4 Build Production-Grade Spark ML Pipeline (Winner Model Family)\n",
    "\n",
    "üìò Learn Covered\n",
    "\n",
    "‚úî Spark ML Pipelines\n",
    "\n",
    "‚úî Feature engineering at scale\n",
    "\n",
    "üõ†Ô∏è Tasks Covered\n",
    "\n",
    "‚úî Task 3 ‚Äì Build Spark ML pipeline\n",
    "\n",
    "‚ö†Ô∏è In this step:\n",
    "\n",
    "We do NOT use scikit-learn\n",
    "\n",
    "We do NOT log to MLflow yet\n",
    "\n",
    "We focus on production readiness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a216b4bd-f538-4569-ae68-9e48825dd208",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Design Decision (Very Important)\n",
    "\n",
    "Based on your results:\n",
    "\n",
    "Model\tR¬≤\n",
    "Random Forest\t0.998 ‚úÖ\n",
    "Decision Tree\t0.952\n",
    "Linear Regression\t0.591\n",
    "‚úÖ Chosen Production Model Family\n",
    "\n",
    "\n",
    "\n",
    "üëâ Decision Tree in Spark = production-ready + explainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "91a8280b-61b3-4d9a-9ffe-0e44a46ee618",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Define Spark Features (VectorAssembler)"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"views\"],   \n",
    "    outputCol=\"features\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5cccf097-7cd2-469b-a3f2-5a9a6e426b3f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "‚úî Feature engineering at scale\n",
    "\n",
    "‚úî No Pandas\n",
    "\n",
    "‚úî Works on millions of rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d11c5b18-e259-479b-bc2c-22341ca8e66f",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Define Spark ML Model"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import DecisionTreeRegressor\n",
    "\n",
    "dt = DecisionTreeRegressor(\n",
    "    featuresCol=\"features\",\n",
    "    labelCol=\"purchases\",\n",
    "    maxDepth=5\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7931102e-2ae1-4911-93e4-1a3c63b91b4e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Tree-based\n",
    "‚úî Hyperparameter explicitly defined\n",
    "‚úî Prevents overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "701749a2-b61b-4990-aee8-714ded8b3062",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Build Spark ML Pipeline"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "\n",
    "pipeline = Pipeline(stages=[\n",
    "    assembler,\n",
    "    dt\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e7030740-2ac1-4d83-adf9-eb0ef341aeb5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "‚úî Reproducible\n",
    "‚úî Versionable\n",
    "‚úî Production-grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e9918a84-d42f-44b0-95c3-91634ec2f275",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Train/Test Split (Spark Native)"
    }
   },
   "outputs": [],
   "source": [
    "spark_df = spark.table(\"gold.products\")\n",
    "\n",
    "train_df, test_df = spark_df.randomSplit([0.8, 0.2], seed=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "306ad04d-6c92-474e-91d4-bf05e5166e96",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "‚úî Distributed\n",
    "‚úî Deterministic split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a547b6c-9974-4b40-9875-514654caf945",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Train Pipeline Model"
    }
   },
   "outputs": [],
   "source": [
    "pipeline_model = pipeline.fit(train_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "48e983cd-c51c-4931-ab71-d646a6f17577",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "‚úî One command\n",
    "‚úî Entire workflow captured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e6204ae3-cd2d-4a5c-bab4-673210603bc2",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Quick Evaluation (Spark)"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "predictions = pipeline_model.transform(test_df)\n",
    "\n",
    "evaluator = RegressionEvaluator(\n",
    "    labelCol=\"purchases\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"r2\"\n",
    ")\n",
    "\n",
    "r2 = evaluator.evaluate(predictions)\n",
    "print(f\"Spark Decision Tree R¬≤: {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e55f7cfa-b000-4170-8332-638f795e4c06",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#STEP 5 ‚Äì Select Best Model & Summarize Learnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "91564961-938f-47ef-96dc-dc7ae9d22c8f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Models trained & compared\n",
    "\n",
    "Model\tFramework\tR¬≤\tVerdict\n",
    "\n",
    "Linear Regression\tsklearn\t~0.59\tStrong baseline\n",
    "\n",
    "Decision Tree\tsklearn\t~0.95\tOverfit\n",
    "\n",
    "Random Forest\tsklearn\t~0.99\tSevere overfit\n",
    "\n",
    "Decision Tree\tSpark ML\t~0.05\tHonest, scalable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b2f3c57c-7a80-4455-85ea-a289328126af",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#LOG SPARK DECISION TREE MODEL TO MLFLOW\n",
    "\n",
    "This step covers MLflow components:\n",
    "\n",
    "Experiment tracking\n",
    "\n",
    "Model logging\n",
    "\n",
    "Metrics logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "556d901f-40e4-45cd-b0d3-0c6ec6de8d60",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#FULL SPARK DECISION TREE PIPELINE, TRAIN, EVALUATE & LOG "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b81e938-426b-4d12-9b9d-a490ae80b226",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import DecisionTreeRegressor\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "import mlflow\n",
    "import mlflow.spark\n",
    "from mlflow.models.signature import infer_signature\n",
    "\n",
    "# -------------------------------\n",
    "# 1Ô∏è‚É£ Prepare features & train/test split\n",
    "# -------------------------------\n",
    "feature_cols = [\"views\"]  # your features\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
    "\n",
    "# Decision Tree model\n",
    "dt = DecisionTreeRegressor(featuresCol=\"features\", labelCol=\"purchases\")\n",
    "\n",
    "# Pipeline\n",
    "pipeline = Pipeline(stages=[assembler, dt])\n",
    "\n",
    "# Train model\n",
    "pipeline_model = pipeline.fit(train_df)\n",
    "\n",
    "# -------------------------------\n",
    "# 2Ô∏è‚É£ Evaluate on test data\n",
    "# -------------------------------\n",
    "predictions = pipeline_model.transform(test_df)\n",
    "evaluator = RegressionEvaluator(\n",
    "    labelCol=\"purchases\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"r2\"\n",
    ")\n",
    "r2 = evaluator.evaluate(predictions)\n",
    "print(f\"‚úÖ Spark Decision Tree R¬≤: {r2:.4f}\")\n",
    "\n",
    "# -------------------------------\n",
    "# 3Ô∏è‚É£ Infer model signature for MLflow\n",
    "# -------------------------------\n",
    "signature = infer_signature(test_df[feature_cols], predictions[\"prediction\"])\n",
    "\n",
    "# -------------------------------\n",
    "# 4Ô∏è‚É£ Log model to MLflow\n",
    "# -------------------------------\n",
    "mlflow.set_experiment(\"/Users/ram.katneni@gmail.com/day13_spark_dt\")\n",
    "\n",
    "with mlflow.start_run() as run:\n",
    "    mlflow.spark.log_model(\n",
    "        spark_model=pipeline_model,\n",
    "        artifact_path=\"spark_dt_model\",\n",
    "        dfs_tmpdir=\"/Volumes/workspace/ml_models/mlflow_tmp\",  # UC temp path\n",
    "        signature=signature\n",
    "    )\n",
    "    mlflow.log_metric(\"r2\", r2)\n",
    "    run_id = run.info.run_id\n",
    "    print(f\"MLflow Run ID: {run_id}\")\n",
    "\n",
    "# -------------------------------\n",
    "# 5Ô∏è‚É£ Register model to Unity Catalog\n",
    "# -------------------------------\n",
    "model_name = \"workspace.ml_models.dt_model_uc\"\n",
    "\n",
    "# Register model in UC\n",
    "model_uri = f\"runs:/{run_id}/spark_dt_model\"\n",
    "mlflow.register_model(model_uri=model_uri, name=model_name)\n",
    "\n",
    "print(f\"Model registered to UC: {model_name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e8ebb775-73c5-41de-8881-3a029e5499bf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Hyperparameter Tuning for Spark Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d9380cbe-fb36-4ece-a9cf-b7c54a33bd69",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS workspace.ml_models.ecommerce_features (\n",
    "  views BIGINT,\n",
    "  purchases BIGINT\n",
    ")\n",
    "USING DELTA\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "22b854b2-dbf2-46a4-aab3-547277244117",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "INSERT INTO workspace.ml_models.ecommerce_features VALUES\n",
    "(10,1),(20,2),(30,3),(40,5),(50,8),\n",
    "(60,13),(70,21),(80,34),(90,55),(100,89)\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7c011e13-0d00-46a2-8778-2c783868c7a2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data = spark.table(\"workspace.ml_models.ecommerce_features\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "60c72080-ff57-4b92-8e77-94da09b43576",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ================================\n",
    "# DAY 13 ‚Äì Model Comparison & Hyperparameter Tuning\n",
    "# ================================\n",
    "\n",
    "# -------------------------------\n",
    "# 0Ô∏è‚É£ Imports & Environment Setup\n",
    "# -------------------------------\n",
    "import os\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import DecisionTreeRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml import Pipeline\n",
    "import mlflow\n",
    "import mlflow.spark\n",
    "from mlflow.models.signature import infer_signature\n",
    "import pandas as pd\n",
    "\n",
    "# -------------------------------\n",
    "# 1Ô∏è‚É£ Environment variables\n",
    "# -------------------------------\n",
    "# Required for Spark ML on Shared / Serverless clusters\n",
    "os.environ[\"SPARKML_TEMP_DFS_PATH\"] = \"/Volumes/workspace/ml_models/mlflow_tmp\"\n",
    "\n",
    "# MLflow experiment (USER path ‚Äì NOT UC)\n",
    "experiment_name = \"/Users/ram.katneni@gmail.com/day13_purchases_regression\"\n",
    "\n",
    "if mlflow.get_experiment_by_name(experiment_name) is None:\n",
    "    mlflow.create_experiment(experiment_name)\n",
    "\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "# -------------------------------\n",
    "# 2Ô∏è‚É£ Load & Prepare Data\n",
    "# -------------------------------\n",
    "data = spark.table(\"workspace.ml_models.ecommerce_features\")\n",
    "\n",
    "feature_cols = [\"views\"]          # raw feature only\n",
    "label_col = \"purchases\"\n",
    "\n",
    "train_df, test_df = data.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# -------------------------------\n",
    "# 3Ô∏è‚É£ Spark ML Pipeline\n",
    "# -------------------------------\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=feature_cols,\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "\n",
    "dt = DecisionTreeRegressor(\n",
    "    featuresCol=\"features\",\n",
    "    labelCol=label_col\n",
    ")\n",
    "\n",
    "pipeline = Pipeline(stages=[assembler, dt])\n",
    "\n",
    "# -------------------------------\n",
    "# 4Ô∏è‚É£ Hyperparameter Tuning\n",
    "# -------------------------------\n",
    "paramGrid = (\n",
    "    ParamGridBuilder()\n",
    "    .addGrid(dt.maxDepth, [2, 5, 10])\n",
    "    .addGrid(dt.minInstancesPerNode, [1, 5, 10])\n",
    "    .build()\n",
    ")\n",
    "\n",
    "evaluator = RegressionEvaluator(\n",
    "    labelCol=label_col,\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"rmse\"   # RMSE is safer than R¬≤\n",
    ")\n",
    "\n",
    "crossval = CrossValidator(\n",
    "    estimator=pipeline,\n",
    "    estimatorParamMaps=paramGrid,\n",
    "    evaluator=evaluator,\n",
    "    numFolds=3,\n",
    "    parallelism=2\n",
    ")\n",
    "\n",
    "# -------------------------------\n",
    "# 5Ô∏è‚É£ Train + MLflow + UC Registration (FIXED)\n",
    "# -------------------------------\n",
    "mlflow.end_run()\n",
    "\n",
    "with mlflow.start_run(run_name=\"Hyperparameter_Tuning_DT_UC\"):\n",
    "\n",
    "    cv_model = crossval.fit(train_df)\n",
    "    best_model = cv_model.bestModel\n",
    "    best_dt = best_model.stages[-1]\n",
    "\n",
    "    predictions = best_model.transform(test_df)\n",
    "    rmse = evaluator.evaluate(predictions)\n",
    "\n",
    "    print(f\"Best DT: depth={best_dt.getMaxDepth()}, minInstances={best_dt.getMinInstancesPerNode()}\")\n",
    "    print(f\"Test RMSE: {rmse}\")\n",
    "\n",
    "    # -------------------------------\n",
    "    # üîë CREATE INPUT / OUTPUT EXAMPLES\n",
    "    # -------------------------------\n",
    "    input_example = (\n",
    "        train_df\n",
    "        .select(feature_cols)\n",
    "        .limit(5)\n",
    "        .toPandas()\n",
    "    )\n",
    "\n",
    "    output_example = (\n",
    "        best_model\n",
    "        .transform(train_df.limit(5))\n",
    "        .select(\"prediction\")\n",
    "        .toPandas()\n",
    "    )\n",
    "\n",
    "    signature = infer_signature(input_example, output_example)\n",
    "\n",
    "    # Log params & metrics\n",
    "    mlflow.log_param(\"maxDepth\", best_dt.getMaxDepth())\n",
    "    mlflow.log_param(\"minInstancesPerNode\", best_dt.getMinInstancesPerNode())\n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "\n",
    "    # -------------------------------\n",
    "    # ‚úÖ UC-COMPLIANT MODEL LOGGING\n",
    "    # -------------------------------\n",
    "    mlflow.spark.log_model(\n",
    "        best_model,\n",
    "        artifact_path=\"dt_model_spark\",\n",
    "        signature=signature,\n",
    "        input_example=input_example,\n",
    "        registered_model_name=\"workspace.ml_models.dt_model_uc\"\n",
    "    )\n",
    "\n",
    "    print(\"‚úÖ Model logged WITH signature and registered in Unity Catalog\")\n",
    "\n",
    "# -------------------------------\n",
    "# 6Ô∏è‚É£ Feature Importance\n",
    "# -------------------------------\n",
    "fi_df = pd.DataFrame(\n",
    "    zip(feature_cols, best_dt.featureImportances),\n",
    "    columns=[\"feature\", \"importance\"]\n",
    ").sort_values(\"importance\", ascending=False)\n",
    "\n",
    "print(fi_df)\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Model Comparison & Feature Engineering",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
